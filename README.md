# Node + TypeScript + `node-llama-cpp`

## Get started
Install node modules and download the model files used by `node-llama-cpp`:
```bash
npm install
```

Start the project:
```bash
npm start
```

> Generated using `npm create node-llama-cpp@latest` ([learn more](https://node-llama-cpp.withcat.ai/guide/))

## Quick chat specific model

From terminal:
```bash
npx --no node-llama-cpp chat models/DeepSeek-R1-Distill-Qwen-7B-Q4_K_M.gguf
```
